{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing with PyTorch\n",
    "In this notebook we will go through checkpointing your model with PyTorch.\n",
    "\n",
    "## Setting up model and dataset\n",
    "For this example we will use [Tiny ImageNet](https://www.kaggle.com/c/tiny-imagenet/overview) which is similar to ImageNet but lower resolution (64x64), fewer images (100 k) and fewer labels (200). For this dataset we will use a variant of the ResNet architecture wich is a type of Convolutional Neural Network with residual connections. For the sake of this tutorial you do not need to understand the details about the model or the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from fnmatch import fnmatch\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Custom Type Hints https://peps.python.org/pep-0484/\n",
    "LoadedFromZip = Tuple[str, object]  \n",
    "DataPoint = Tuple[torch.FloatTensor, int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(split='train'):\n",
    "    '''Construct a dataset for the tiny-imagenet-200 dataset'''\n",
    "    path_to_dataset = '/mimer/NOBACKUP/Datasets/tiny-imagenet-200/tiny-imagenet-200.zip'\n",
    "\n",
    "    # Open the zip file\n",
    "    ziphandle = zipfile.ZipFile(path_to_dataset)\n",
    "    \n",
    "    # Filter data images based on the split (train and val)\n",
    "    filenames = [\n",
    "        filename for filename in ziphandle.namelist()\n",
    "        if f'/{split}/' in filename and filename.endswith('.JPEG')\n",
    "    ]\n",
    "    \n",
    "    # Set length of dataset\n",
    "    dataset_len = len(filenames)\n",
    "\n",
    "    # Read wnids.txt to create label mapping\n",
    "    for filename in ziphandle.namelist():\n",
    "        if filename.endswith('wnids.txt'):\n",
    "            with ziphandle.open(filename) as txtfile:\n",
    "                wnids = txtfile.read().decode('utf-8').split()\n",
    "                break\n",
    "    wnid2label = {wnid: label for label, wnid in enumerate(wnids)}\n",
    "\n",
    "    # Utility function for getting wnid from filename\n",
    "    if split == 'train':\n",
    "        def get_wnid(filename: str) -> str:\n",
    "            return filename.split(\"/\")[-1].split('_')[0]\n",
    "    elif split == 'val':\n",
    "        # Parse annotations in validation set\n",
    "        filename2wnid = {}\n",
    "        for filename in ziphandle.namelist():\n",
    "            if filename.endswith('val_annotations.txt'):\n",
    "                with ziphandle.open(filename) as txtfile:\n",
    "                    for line in txtfile.read().decode('utf-8').split('\\n'):\n",
    "                        if line.startswith('val'):\n",
    "                            fname, wnid, *_ = line.split('\\t')\n",
    "                            filename2wnid[fname] = wnid\n",
    "                break\n",
    "        \n",
    "        def get_wnid(filename: str) -> str:\n",
    "            return filename2wnid.get(os.path.basename(filename), None)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Can't determine labels for split {split}.\")\n",
    "\n",
    "    # Convert stream to image tensor and label\n",
    "    def parse_tiny_imagenet(filename: str) -> DataPoint:\n",
    "        '''Parse filename and image stream into label and image tensors'''\n",
    "        wnid = get_wnid(filename)\n",
    "        label = wnid2label.get(wnid, -1)\n",
    "\n",
    "        with ziphandle.open(filename) as stream:\n",
    "            img_array = np.array(Image.open(stream))\n",
    "            if img_array.ndim < 3:\n",
    "                # Greyscale to RGB\n",
    "                img_array = np.repeat(img_array[..., np.newaxis], 3, -1)\n",
    "\n",
    "            img_tensor = torch.from_numpy(img_array)\n",
    "            img_tensor = img_tensor.permute(2, 0, 1)  # Convert to (C, H, W)\n",
    "            return img_tensor.float(), label\n",
    "\n",
    "    # Apply the parse function to all filenames\n",
    "    dataset = [parse_tiny_imagenet(filename) for filename in filenames]\n",
    "    \n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(split=\"train\")\n",
    "val_dataset = build_dataset(split=\"val\")\n",
    "\n",
    "load_kws = dict(\n",
    "    num_workers=4,\n",
    "    batch_size=512,\n",
    "    prefetch_factor=512,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, **load_kws)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, **load_kws)\n",
    "\n",
    "# ResNet-18\n",
    "pretrained = False\n",
    "model = resnet18(weights=None, num_classes=200)\n",
    "if pretrained:\n",
    "    # If we like we can use weights trained on ImageNet 1000\n",
    "    pretrained_state_dict = resnet18(weights=\"IMAGENET1K_V2\", num_classes=1000).state_dict()\n",
    "    # However, the last fully connected layer is the wrong shape    \n",
    "    for key in [\"fc.weight\", \"fc.bias\"]:\n",
    "        del pretrained_state_dict[key]\n",
    "    model.load_state_dict(pretrained_state_dict, strict=False)\n",
    "\n",
    "# Optimizer\n",
    "opt = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we come to the important part, the training. In this part we will have to include the checkpointing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, opt, n_epochs, checkpoint_path, device=device):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    total_steps = n_epochs * n_batches\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Training epoch\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            est = model(images)\n",
    "            \n",
    "            # Calculate loss and backpropagate\n",
    "            loss = loss_func(est, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            counter += 1\n",
    "            print(f\"\\rProgress: {100 * counter / total_steps:4.1f} %  ({counter}/{total_steps})\", end=\"\")\n",
    "        \n",
    "        # Average training loss\n",
    "        train_loss /= n_batches\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc = validate(model, device=device)\n",
    "        print(f\"\\rEpoch {epoch}, Train loss {train_loss}, Val loss {val_loss}, Val acc {val_acc}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": opt.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "\n",
    "\n",
    "def validate(model, device=device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0.0\n",
    "        n_batches = len(val_loader)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            est = model(images)\n",
    "            loss += loss_func(est, labels).item()\n",
    "            acc = (labels == est.argmax(1)).float().mean().item()\n",
    "            \n",
    "            # Accuracy calculation\n",
    "            #_, predicted = torch.max(est, 1)\n",
    "            #correct += (predicted == labels).sum().item()\n",
    "            #total += labels.size(0)\n",
    "        \n",
    "        # Average loss and accuracy\n",
    "        loss /= n_batches\n",
    "        #accuracy = correct / total\n",
    "\n",
    "        return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss 5.111716720522667, Val loss 4.836109328269958, Val acc 0.04411764815449715\n",
      "Epoch 1, Train loss 4.5856974319535855, Val loss 4.557662415504455, Val acc 0.06617647409439087\n",
      "Epoch 2, Train loss 4.188210615089962, Val loss 4.187456750869751, Val acc 0.12132353335618973\n",
      "Epoch 3, Train loss 3.843514551921767, Val loss 3.8874372959136965, Val acc 0.17279411852359772\n",
      "Epoch 4, Train loss 3.5770948091331793, Val loss 3.718472933769226, Val acc 0.16544117033481598\n",
      "CPU times: user 2min 26s, sys: 10.2 s, total: 2min 36s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(model, opt, n_epochs=5, checkpoint_path=\"checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(weights=None, num_classes=200)\n",
    "checkpoint = torch.load(\"checkpoint.pt\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss: 3.7185\n",
      "Accuracy:        0.1654\n"
     ]
    }
   ],
   "source": [
    "loss, acc = validate(model)\n",
    "print(f'''\n",
    "Validation loss: {loss:.4f}\n",
    "Accuracy:        {acc:.4f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "1. Write a `train_from_checkpoint` function below that given the path to a checkpoint continues training from there\n",
    "2. Modify the `train_from_checkpoint` function to also save the best checkpoint so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
