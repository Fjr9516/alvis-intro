{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing with PyTorch\n",
    "In this notebook we will go through checkpointing your model with PyTorch.\n",
    "\n",
    "## Setting up model and dataset\n",
    "For this example we will use [Tiny ImageNet](https://www.kaggle.com/c/tiny-imagenet/overview) which is similar to ImageNet but lower resolution (64x64) and fewer images (100 k). For this dataset we will use a variant of the ResNet architecture wich is a type of Convolutional Neural Network with residual connections. For the sake of this tutorial you do not need to understand the details about the model or the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we move the dataset to TMPDIR if one is available\n",
    "import os\n",
    "\n",
    "if \"TMPDIR\" in os.environ:\n",
    "    data_path = os.path.join(os.environ[\"TMPDIR\"], \"tiny-imagenet-200/\")\n",
    "    if not os.path.isdir(data_path):\n",
    "        !cp \"/cephyr/NOBACKUP/Datasets/tiny-imagenet-200/tiny-imagenet-200.zip\" \"$TMPDIR\"\n",
    "        !unzip -qn \"$TMPDIR/tiny-imagenet-200.zip\" -d \"$TMPDIR\"\n",
    "else:\n",
    "    data_path = \"/cephyr/NOBACKUP/Datasets/tiny-imagenet-200\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, layers, Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNetIterator(DirectoryIterator):\n",
    "    '''Help class when loading TinyImageNet.'''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        parent_directory,\n",
    "        subset,\n",
    "        image_data_generator,\n",
    "        target_size=(64, 64),\n",
    "        color_mode='rgb',\n",
    "        classes=None,\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        data_format='channels_last',\n",
    "        save_to_dir=None,\n",
    "        save_prefix='',\n",
    "        save_format='png',\n",
    "        follow_links=False,\n",
    "        interpolation='nearest',\n",
    "        dtype='float32',\n",
    "    ):\n",
    "        train_directory = os.path.join(parent_directory, \"train\")\n",
    "        if subset==\"training\":\n",
    "            return super().__init__(\n",
    "                train_directory,\n",
    "                image_data_generator,\n",
    "                target_size=target_size,\n",
    "                color_mode=color_mode,\n",
    "                classes=classes,\n",
    "                class_mode=class_mode,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=shuffle,\n",
    "                seed=seed,\n",
    "                data_format=data_format,\n",
    "                save_to_dir=save_to_dir,\n",
    "                save_prefix=save_prefix,\n",
    "                save_format=save_format,\n",
    "                follow_links=follow_links,\n",
    "                subset=subset,\n",
    "                interpolation=interpolation,\n",
    "                dtype=dtype,\n",
    "            )\n",
    "        elif subset==\"validation\":\n",
    "            directory = os.path.join(parent_directory, \"val\")\n",
    "        else:\n",
    "            raise ValueError(f'Value of subset should be \"training\" or \"validation\",  not {subset}.')\n",
    "        \n",
    "        # Modified Directory Iterator __init__\n",
    "        super(DirectoryIterator, self).set_processing_attrs(\n",
    "            image_data_generator=image_data_generator,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            data_format=data_format,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            subset=subset,\n",
    "            interpolation=interpolation,\n",
    "        )\n",
    "        self.directory = directory\n",
    "        self.classes = classes\n",
    "        if class_mode not in self.allowed_class_modes:\n",
    "            raise ValueError(f'Invalid class_mode: {class_mode}; expected one of: {self.allowed_class_modes}')\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # First, count the number of samples and classes.\n",
    "        class_names = classes\n",
    "        if not class_names:\n",
    "            class_names = []\n",
    "            for subdir in sorted(os.listdir(train_directory)):\n",
    "                if os.path.isdir(os.path.join(train_directory, subdir)):\n",
    "                    class_names.append(subdir)\n",
    "        self.num_classes = len(class_names)\n",
    "        self.class_indices = dict(zip(class_names, range(len(class_names))))\n",
    "\n",
    "        # Get map between filename and class index                 \n",
    "        with open(os.path.join(directory, \"val_annotations.txt\"), \"r\") as f:\n",
    "            filenames, classes = zip(*[\n",
    "                (os.path.join(\"images\", fn), self.class_indices[class_name])\n",
    "                for fn, class_name, _, _, _, _\n",
    "                in csv.reader(f, delimiter=\"\\t\")\n",
    "            ])\n",
    "\n",
    "        self.filenames = filenames\n",
    "        self.samples = len(self.filenames)\n",
    "        self.classes = np.array(classes, dtype='int32')\n",
    "\n",
    "        print(f'Found {self.samples} images belonging to {self.num_classes} classes.')\n",
    "        self._filepaths = [os.path.join(self.directory, fn) for fn in self.filenames]\n",
    "        grandparent_class = self.__class__.__mro__[2]  # sorry, not nice code\n",
    "        super(grandparent_class, self).__init__(self.samples, batch_size, shuffle, seed)        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size + 1\n",
    "        \n",
    "\n",
    "class TinyImageNetGenerator(ImageDataGenerator, TinyImageNetIterator):\n",
    "    \n",
    "    \n",
    "    def __bool__(self):\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def flow_from_directory(\n",
    "        self,\n",
    "        parent_directory,\n",
    "        subset,\n",
    "        *,\n",
    "        target_size=(64, 64),\n",
    "        color_mode=\"rgb\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return TinyImageNetIterator(\n",
    "            parent_directory,\n",
    "            subset,\n",
    "            self,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_parent = data_path\n",
    "\n",
    "batch_size = 512\n",
    "train_batches = TinyImageNetGenerator().flow_from_directory(dir_parent, \"training\", batch_size=batch_size)\n",
    "val_batches = TinyImageNetGenerator().flow_from_directory(dir_parent, \"validation\", batch_size=batch_size)\n",
    "\n",
    "train_set = Dataset.from_generator(\n",
    "    lambda: train_batches,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 3], [None, 200])\n",
    ")\n",
    "val_set = Dataset.from_generator(\n",
    "    lambda: val_batches,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 64, 64, 3], [None, 200])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(layers.Layer):\n",
    "    \n",
    "    def __init__(self, filters, strides=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv1 = layers.Conv2D(filters, 3, strides=strides, padding=\"same\", use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization(epsilon=1e-5)\n",
    "        self.conv2 = layers.Conv2D(filters, 3, padding=\"same\", use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization(epsilon=1e-5)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        prev_shape = x.shape\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        identity = inputs if self.downsample is None else self.downsample(inputs)\n",
    "    \n",
    "        return self.relu(x + identity)\n",
    "\n",
    "\n",
    "class ResNet(keras.Model):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_layers,\n",
    "        num_classes=1000,\n",
    "        zero_init_residual=False,\n",
    "        groups=1,\n",
    "        downsample=None,\n",
    "        name=\"resnet\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.block = ResidualBlock\n",
    "        \n",
    "        self.in_filters = 64\n",
    "        self.dilation = 1\n",
    "        self.groups = 1\n",
    "        \n",
    "        # Defining layers\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv1 = layers.Conv2D(filters=64, kernel_size=7, strides=2, padding=\"same\", use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization(epsilon=1e-5)\n",
    "        self.maxpool = layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\")\n",
    "        self.layer1 = self._make_layer(64, n_layers[0])\n",
    "        self.layer2 = self._make_layer(128, n_layers[1], strides=2)\n",
    "        self.layer3 = self._make_layer(256, n_layers[2], strides=2)\n",
    "        self.layer4 = self._make_layer(512, n_layers[3], strides=2)\n",
    "        self.avgpool = layers.AveragePooling2D(pool_size=1)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "    \n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, layers.Conv2D):\n",
    "                layer.kernel_initializer = keras.initializers.VarianceScaling(\n",
    "                    scale=2.0,\n",
    "                    mode=\"fan_out\",\n",
    "                )        \n",
    "    \n",
    "    \n",
    "    def _make_layer(self, filters, n_blocks, strides=1):\n",
    "        block = self.block\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        check_singular_strides = lambda strides: (tuple(strides) != (1, 1) if isinstance(strides, Iterable) else strides != 1)\n",
    "        if check_singular_strides(strides) or self.in_filters != filters:\n",
    "            downsample = keras.Sequential([\n",
    "                layers.Conv2D(filters, 1, strides=strides, use_bias=False),\n",
    "                layers.BatchNormalization(epsilon=1e-5),\n",
    "            ])\n",
    "        \n",
    "        layer = keras.Sequential()\n",
    "        layer.add(block(filters, strides=strides, downsample=downsample))\n",
    "        self.in_filters = filters\n",
    "        for _ in range(1, n_blocks):\n",
    "            layer.add(block(filters))\n",
    "    \n",
    "        return layer\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet([2, 2, 2, 2], num_classes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we come to the important part, the profiling. In this part we will have to include the checkpointing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling is done via callback\n",
    "profiling_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs/base-tf',\n",
    "    histogram_freq=1,\n",
    "    profile_batch=\"15,25\",\n",
    ")\n",
    "\n",
    "# Compile model as usual\n",
    "resnet18.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Remember to add profiling callback\n",
    "resnet18.fit(\n",
    "    train_set,\n",
    "    epochs=2,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    callbacks=[profiling_callback],\n",
    "    validation_data=val_set,\n",
    "    validation_steps=len(val_batches),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "1. Look at the profiling results in tensorboard. To do this, follow the instructions in README.md\n",
    "2. Try to follow the Performance Recomendation and try again by modifying the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling is done via callback\n",
    "profiling_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs/improved-tf',\n",
    "    histogram_freq=1,\n",
    "    profile_batch=\"15,25\",\n",
    ")\n",
    "\n",
    "# Compile model as usual\n",
    "resnet18.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Remember to add profiling callback\n",
    "resnet18.fit(\n",
    "    train_set,\n",
    "    epochs=2,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    callbacks=[profiling_callback],\n",
    "    validation_data=val_set,\n",
    "    validation_steps=len(val_batches),\n",
    "    verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
