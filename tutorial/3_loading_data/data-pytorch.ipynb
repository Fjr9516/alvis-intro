{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data with PyTorch\n",
    "In this notebook we will investigate a few different ways to handle data with PyTorch on Alvis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your own data\n",
    "In many cases you have a dataset in mind that you've already acquired and are keeping in your home folder or perhaps more probable in a storage project.\n",
    "\n",
    "In this section we will use the dataset in `data.tar.gz`, first let us take a look at it.\n",
    "\n",
    "### The file tree\n",
    "To see what is contained in a tar file the command `tar -tf my_tarfile.tar` is useful. However, we might want to specifically know some things about the directory structure and filenames. This is done in the below script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# This will find the directories and files that do not have names ending with .png\n",
    "# and then count the number of files with names containing \".png\" for each of these\n",
    "echo \" #Files   Path\"\n",
    "echo \"==================\"\n",
    "for dir in $(tar --exclude=\"*.png\" -tf data.tar.gz); do\n",
    "    n_files=$(tar -tf data.tar.gz --wildcards \"$dir*.png\" | wc -l)\n",
    "    printf \"  %5s   %s\\n\" \"$n_files\" \"$dir\"\n",
    "done\n",
    "\n",
    "# List the 5 first and last png filenames in /data/1/\n",
    "echo  # New line\n",
    "echo \" Typical filenames\"\n",
    "echo \"===================\"\n",
    "tar -tf data.tar.gz --wildcards --no-anchored \"data/1/*.png\" | (head -n 5; echo \"...\"; tail -n 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE:*** For this tar file there were \"only\" 60000 files, for archives that are much larger these operations will mean a significant FileIO and should be avoided as much as possible. If there is a README in connection with the dataset it is wise to take a look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some of the data\n",
    "Now we know the file structure of the data. Let us now get acquainted with the data a bit.\n",
    "\n",
    "First extract a small subset of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Extract the first 49 files\n",
    "tar -xvf data.tar.gz --wildcards \"data/*/im-000[0-4]?.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us take a look at these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax_grid = plt.subplots(7, 7, figsize=(15, 15))\n",
    "for ix, ax in enumerate(ax_grid.flatten()):\n",
    "    # Get path to file and label\n",
    "    filepath = glob(f\"data/*/im-{ix:05d}.png\")[0]\n",
    "    _, label, filename = filepath.split(\"/\")\n",
    "    \n",
    "    # Add to axis\n",
    "    img = mpimg.imread(filepath)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Digit {int(label) - 1}\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labels are offset by 1 compared to the digits. The dataset is actually a modified version of the MNIST handwritten digit training database. The images have been shrunk to only 9x9 pixels and monochrome images to reduce the size of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier from this data\n",
    "Now we have some understanding of what the database does and we are ready to do some ML on it.\n",
    "\n",
    "First we will define our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 (3, 3) convolutional filters followed by a dense layer\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 10, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(640, 10),\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we come to the step were we will load the data. When we have a dataset with the structure \"root/class/input\" then we can use `torchvision.dataset.DatasetFolder` or in the case of images `torchvision.dataset.ImageFolder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(glob(\"data/?/*.png\")) < 60000:\n",
    "    import warnings\n",
    "    warnings.warn(\"\\\"data/\\\" is not fully unpacked!\")\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = ImageFolder(\"data\", transform=transform)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(\n",
    "    dataloader,\n",
    "    model,\n",
    "    opt,\n",
    "    loss_func,\n",
    "    n_epochs=3,\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        n_batches = len(dataloader)\n",
    "        avg_loss = 0.0\n",
    "        for x, label in dataloader:\n",
    "            x, label = x.to(device), label.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = loss_func(logits, label)\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        avg_loss /= n_batches\n",
    "        print(f\"Loss: {avg_loss}\")\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dataloader, model, opt, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    " 1. Make yourself acquainted with the above code.\n",
    " 2. In the future, if you have data on Mimer you can probably skip step 3.\n",
    " 3. Take a look at `jobscript-pytorch.sh` in this script we will unpack the dataset on \\$TMPDIR and then train the model on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using available datasets\n",
    "Some common public datasets are available at `/cephyr/NOBACKUP/Datasets`, if there are some specific dataset you would like to see added you can create a request at [SNIC-support](https://supr.snic.se/support/).\n",
    "\n",
    "In this part we will access the processed MNIST dataset available at `/cephyr/NOBACKUP/Datasets/MNIST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 (3, 3) convolutional filters followed by a dense layer\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 10, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(6760, 10),\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it is really simple as this dataset has been processed for use with `torchvision.datasets.MNIST` and all we need to do is supply the correct path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(\"/cephyr/NOBACKUP/Datasets\", transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dataloader, model, opt, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data through the torchvision API\n",
    "At `torchvision.datasets`, `torchaudio.datasets` and `torchtext.datasets` all have similar APIs that can be used to download datasets that do not exist in `/cephyr/NOBACKUP/Datasets`. However, note that this can take some time and you will have to store them yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
